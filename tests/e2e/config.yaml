model_id: openai/whisper-tiny
dataset_id: example_data/custom
language: English
repo_name: e2e_test
n_train_samples: -1
n_test_samples: -1

training_hp:
    push_to_hub: False
    hub_private_repo: False
    max_steps: 2
    per_device_train_batch_size: 8
    gradient_accumulation_steps: 1
    learning_rate: 1e-5
    warmup_steps: 1
    gradient_checkpointing: False
    fp16: False
    eval_strategy: steps
    per_device_eval_batch_size: 2
    predict_with_generate: True
    generation_max_length: 225
    save_steps: 1
    logging_steps: 1
    load_best_model_at_end: True
    save_total_limit: 1
    metric_for_best_model: wer
    greater_is_better: False
